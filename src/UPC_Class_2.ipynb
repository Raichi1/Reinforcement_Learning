{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g5uuLz-FS3_B"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classes and Functions\n",
        "\n",
        "Execute all cells."
      ],
      "metadata": {
        "id": "g5uuLz-FS3_B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqmXZoReNPIQ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class Grid_Environment:\n",
        "    def __init__ (self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.state = (1,1)\n",
        "        self.goal = (X,Y)\n",
        "\n",
        "        states = []\n",
        "        for x in range(X):\n",
        "            for y in range(Y):\n",
        "                states = states + [(x+1,y+1)]\n",
        "        self.states = (*states, )\n",
        "\n",
        "        self.actions = ('w', 's', 'd', 'a' )\n",
        "\n",
        "    moveAction = {\n",
        "        'w': (0,1),\n",
        "        's': (0,-1),\n",
        "        'd': (1,0),\n",
        "        'a': (-1,0)\n",
        "    }\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = (1,1)\n",
        "\n",
        "    def move(self,state,shift):\n",
        "        x = min(max(state[0] + shift[0],1),self.X)\n",
        "        y = min(max(state[1] + shift[1],1),self.Y)\n",
        "        return (x,y)\n",
        "\n",
        "\n",
        "    def reward(self,state, action):\n",
        "        if state == self.goal:\n",
        "            return 0\n",
        "        else:\n",
        "            return -1\n",
        "\n",
        "    def nextState(self,state, action):\n",
        "        nextStates = {}\n",
        "\n",
        "        if state == self.goal:\n",
        "          nextStates[self.goal] = 1.0\n",
        "          return nextStates\n",
        "\n",
        "        next = self.move(state,self.moveAction[action])\n",
        "        nextStates[next] = 1.0\n",
        "\n",
        "        return nextStates\n",
        "\n",
        "    def simulateStep(self,state,action):\n",
        "        r = self.reward(state, action)\n",
        "        nextStates = self.nextState(state,action)\n",
        "        return random.choices( list( nextStates.keys() ), weights = list( nextStates.values() ), k=1 )[0], r\n",
        "\n",
        "\n",
        "    def step(self,action):\n",
        "        self.state, r  = self.simulateStep(self.state,action)\n",
        "        return self.state, r\n",
        "\n",
        "    def render(self):\n",
        "        print('')\n",
        "        for j in range(self.Y,0,-1):\n",
        "            for i in range(1,self.X+1):\n",
        "                if self.state == (i,j):\n",
        "                    print('A',end='')\n",
        "                elif self.goal == (i,j):\n",
        "                    print('G',end='')\n",
        "                else:\n",
        "                    print('*',end='')\n",
        "            print('')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GridWind_Environment(Grid_Environment):\n",
        "    windUp = (0,1)\n",
        "    windDown = (0,-1)\n",
        "    windLeft = (-1,0)\n",
        "\n",
        "    def nextState(self,state, action):\n",
        "        nextStates = {}\n",
        "\n",
        "        if state == self.goal:\n",
        "          nextStates[self.goal] = 1.0\n",
        "          return nextStates\n",
        "\n",
        "        if state[0]/self.X >= 0.5 and state[0] < self.X and state[1]/self.Y > 0.5:\n",
        "          next = self.move(state,self.moveAction[action])\n",
        "          nextStates[next] = 0.5\n",
        "\n",
        "          next = self.move(state,self.moveAction['w'])\n",
        "          if next in nextStates:\n",
        "              nextStates[next] = nextStates[next] + 0.25\n",
        "          else:\n",
        "              nextStates[next] = 0.25\n",
        "\n",
        "          next = self.move(state,self.moveAction['a'])\n",
        "          if next in nextStates:\n",
        "              nextStates[next] = nextStates[next] + 0.25\n",
        "          else:\n",
        "              nextStates[next] =  0.25\n",
        "\n",
        "        elif state[0]/self.X <= 0.5 and state[0] > 1 and state[1]/self.Y <= 0.5:\n",
        "          next = self.move(state,self.moveAction[action])\n",
        "          nextStates[next] = 0.5\n",
        "\n",
        "          next = self.move(state,self.moveAction['s'])\n",
        "          if next in nextStates:\n",
        "              nextStates[next] = nextStates[next] + 0.25\n",
        "          else:\n",
        "              nextStates[next] =  0.25\n",
        "\n",
        "          next = self.move(state,self.moveAction['a'])\n",
        "          if next in nextStates:\n",
        "              nextStates[next] = nextStates[next] + 0.25\n",
        "          else:\n",
        "              nextStates[next] =  0.25\n",
        "        else:\n",
        "          next = self.move(state,self.moveAction[action])\n",
        "          nextStates[next] = 1.0\n",
        "\n",
        "\n",
        "        return nextStates\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        print('')\n",
        "        for j in range(self.Y,0,-1):\n",
        "            for i in range(1,self.X+1):\n",
        "                if self.state == (i,j):\n",
        "                    print('A',end='')\n",
        "                elif self.goal == (i,j):\n",
        "                    print('G',end='')\n",
        "                elif i/self.X >= 0.5 and i < self.X and j/self.Y > 0.5:\n",
        "                    print('$',end='')\n",
        "                elif i/self.X <= 0.5 and i > 1 and j/self.Y <= 0.5:\n",
        "                    print('#',end='')\n",
        "                else:\n",
        "                    print('*',end='')\n",
        "            print('')"
      ],
      "metadata": {
        "id": "w3-qQ_mfQ6js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GridQuad_Environment(Grid_Environment):\n",
        "    Q1 = { 'a' : 'd', 's' : 'w' , 'd' : 'a', 'w':'s' }\n",
        "    Q2 = { 'a' : 'w', 's' : 'a' , 'd' : 's', 'w':'d' }\n",
        "    Q3 = { 'a' : 'w', 's' : 'd' , 'd' : 'a', 'w':'s' }\n",
        "    Q4 = { 'a' : 's', 's' : 'd' , 'd' : 'w', 'w':'a' }\n",
        "\n",
        "    def nextState(self,state, action):\n",
        "        nextStates = {}\n",
        "\n",
        "        if state == self.goal:\n",
        "          nextStates[self.goal] = 1.0\n",
        "          return nextStates\n",
        "\n",
        "        if self.state[0]/self.X <= 0.5 and self.state[1]/self.Y <= 0.5:\n",
        "          next = self.move(state,self.moveAction[self.Q2[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X > 0.5 and self.state[1]/self.Y <= 0.5:\n",
        "          next = self.move(state,self.moveAction[self.Q3[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X <= 0.5 and self.state[1]/self.Y > 0.5:\n",
        "          next = self.move(state,self.moveAction[self.Q4[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X > 0.5 and self.state[1]/self.Y > 0.5:\n",
        "          next = self.move(state,self.moveAction[self.Q1[action]])\n",
        "          nextStates[next] = 1.0\n",
        "\n",
        "        return nextStates\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        print('')\n",
        "        for j in range(self.Y,0,-1):\n",
        "            for i in range(1,self.X+1):\n",
        "                if self.state == (i,j):\n",
        "                    print('A',end='')\n",
        "                elif self.goal == (i,j):\n",
        "                    print('G',end='')\n",
        "                elif i/self.X <= 0.5 and j/self.Y <= 0.5:\n",
        "                    print('$',end='')\n",
        "                elif i/self.X > 0.5 and j/self.Y <= 0.5:\n",
        "                    print('#',end='')\n",
        "                elif i/self.X <= 0.5 and j/self.Y > 0.5:\n",
        "                    print('@',end='')\n",
        "                else:\n",
        "                    print('*',end='')\n",
        "            print('')"
      ],
      "metadata": {
        "id": "DFQ3m3QeX-Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GridQuadInv_Environment(Grid_Environment):\n",
        "    Q1 = { 'a' : 'd', 's' : 'w' , 'd' : 'a', 'w':'s' }\n",
        "    Q2 = { 'a' : 'w', 's' : 'a' , 'd' : 's', 'w':'d' }\n",
        "    Q3 = { 'a' : 'w', 's' : 'd' , 'd' : 'a', 'w':'s' }\n",
        "    Q4 = { 'a' : 's', 's' : 'd' , 'd' : 'w', 'w':'a' }\n",
        "\n",
        "    def nextState(self,state, action):\n",
        "        nextStates = {}\n",
        "\n",
        "        if state == self.goal:\n",
        "          nextStates[self.goal] = 1.0\n",
        "          return nextStates\n",
        "\n",
        "        if self.state[0]/self.X <= 0.3 and self.state[1]/self.Y <= 0.3:\n",
        "          next = self.move(state,self.moveAction[self.Q3[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X > 0.3 and self.state[1]/self.Y <= 0.3:\n",
        "          next = self.move(state,self.moveAction[self.Q4[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X <= 0.3 and self.state[1]/self.Y > 0.3:\n",
        "          next = self.move(state,self.moveAction[self.Q1[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X > 0.3 and self.state[1]/self.Y > 0.3:\n",
        "          next = self.move(state,self.moveAction[self.Q2[action]])\n",
        "          nextStates[next] = 1.0\n",
        "\n",
        "        return nextStates\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        print('')\n",
        "        for j in range(self.Y,0,-1):\n",
        "            for i in range(1,self.X+1):\n",
        "                if self.state == (i,j):\n",
        "                    print('A',end='')\n",
        "                elif self.goal == (i,j):\n",
        "                    print('G',end='')\n",
        "                # elif i/self.X <= 0.3 and j/self.Y <= 0.3:\n",
        "                #     print('$',end='')\n",
        "                # elif i/self.X > 0.3 and j/self.Y <= 0.3:\n",
        "                #     print('#',end='')\n",
        "                # elif i/self.X <= 0.3 and j/self.Y > 0.3:\n",
        "                #     print('@',end='')\n",
        "                else:\n",
        "                    print('*',end='')\n",
        "            print('')"
      ],
      "metadata": {
        "id": "qpfEUwaNhFZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def Simulate(env,maxSteps):\n",
        "  env.reset()\n",
        "  tempo = .25\n",
        "  clear_output(wait=True)\n",
        "  env.render()\n",
        "\n",
        "  steps = 0\n",
        "\n",
        "  while steps < maxSteps:\n",
        "\n",
        "      breakSignal = False\n",
        "      command = input(\"Write 'w', 'a', 's', 'd' to move: \")\n",
        "      for a in command:\n",
        "        s = env.state\n",
        "        if s == env.goal:\n",
        "            breakSignal = True\n",
        "            break\n",
        "        if a in ['w', 'a', 's', 'd']:\n",
        "            env.step(a)\n",
        "            steps += 1\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        env.render()\n",
        "        time.sleep(tempo)\n",
        "      if env.state == env.goal or breakSignal:\n",
        "        break\n",
        "\n",
        "  if env.state == env.goal:\n",
        "    print(f\"Congratulations. You spent {steps} steps to reach the Goal.\")\n",
        "    input(\"Press enter to go to the next task.\")\n",
        "  else:\n",
        "    print(f\"You fail to reach the goal.\")\n",
        "    input(\"Press enter to go to the next task.\")\n",
        "\n",
        "  return steps\n",
        "\n",
        "def EvaluatePolicyMC(env,policy,maxSteps,nSamples):\n",
        "\n",
        "  memSteps = []\n",
        "  memGoals = []\n",
        "\n",
        "  for i in range(nSamples):\n",
        "    env.reset()\n",
        "    steps = 0\n",
        "\n",
        "    while steps < maxSteps:\n",
        "      s = env.state\n",
        "      a = policy[s]\n",
        "      if s == env.goal:\n",
        "          break\n",
        "      if a in ['w', 'a', 's', 'd']:\n",
        "          env.step(a)\n",
        "          steps += 1\n",
        "\n",
        "    if env.state == env.goal:\n",
        "      memGoals = memGoals + [1]\n",
        "      memSteps = memSteps + [steps]\n",
        "    else:\n",
        "      memGoals = memGoals + [0]\n",
        "\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(f'Simulating {(i+1)/nSamples}')\n",
        "\n",
        "  print(f'The goal was rechead {100*np.mean(memGoals)}% of the simulations.')\n",
        "  if len(memSteps) > 0:\n",
        "    print(f'The average steps in simulations that rechead the goal was {np.mean(memSteps)}.')\n",
        "\n",
        "  return memSteps, memGoals\n",
        "\n",
        "def SimulatePolicy(env,policy,maxSteps):\n",
        "  env.reset()\n",
        "  tempo = .25\n",
        "  clear_output(wait=True)\n",
        "  env.render()\n",
        "\n",
        "  steps = 0\n",
        "\n",
        "  while steps < maxSteps:\n",
        "    s = env.state\n",
        "    a = policy[s]\n",
        "    if s == env.goal:\n",
        "        break\n",
        "    if a in ['w', 'a', 's', 'd']:\n",
        "        env.step(a)\n",
        "        steps += 1\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    env.render()\n",
        "    time.sleep(tempo)\n",
        "  if env.state == env.goal:\n",
        "    print(f\"Congratulations. You spent {steps} steps to reach the Goal.\")\n",
        "  else:\n",
        "    print(f\"You fail to reach the goal.\")\n",
        "\n",
        "  return steps\n",
        "\n",
        "def SimulatePlan(env,plan):\n",
        "  env.reset()\n",
        "  tempo = .25\n",
        "  clear_output(wait=True)\n",
        "  env.render()\n",
        "\n",
        "  steps = 0\n",
        "\n",
        "  for a in plan:\n",
        "    s = env.state\n",
        "    if s == env.goal:\n",
        "        break\n",
        "    if a in ['w', 'a', 's', 'd']:\n",
        "        env.step(a)\n",
        "        steps += 1\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    env.render()\n",
        "    time.sleep(tempo)\n",
        "  if env.state == env.goal:\n",
        "    print(f\"Congratulations. You spent {steps} steps to reach the Goal.\")\n",
        "  else:\n",
        "    print(f\"You fail to reach the goal.\")\n",
        "\n",
        "  return steps"
      ],
      "metadata": {
        "id": "pAfI5L1PrZkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution 1: Monte Carlo Evaluation\n",
        "\n",
        "\n",
        "Expand the cells, before executing them."
      ],
      "metadata": {
        "id": "TuxfFuY-efPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def renderPolicy(env,policy):\n",
        "  print('')\n",
        "  for j in range(env.Y,0,-1):\n",
        "      for i in range(1,env.X+1):\n",
        "          if policy[(i,j)] == 'a':\n",
        "              print('<',end='')\n",
        "          elif policy[(i,j)] == 's':\n",
        "              print('v',end='')\n",
        "          elif policy[(i,j)] == 'd':\n",
        "              print('>',end='')\n",
        "          elif policy[(i,j)] == 'w':\n",
        "              print('^',end='')\n",
        "          else:\n",
        "              print('*',end='')\n",
        "      print('')"
      ],
      "metadata": {
        "id": "AJi5zAd6TwyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nX = 20\n",
        "nY = 10\n",
        "\n",
        "env = GridWind_Environment(nX,nY)\n",
        "\n",
        "maxSteps = 100\n",
        "\n",
        "policy = {}\n",
        "\n",
        "for s in env.states:\n",
        "  policy[s] = 'd'\n",
        "\n",
        "for j in range(1,env.Y+1):\n",
        "  policy[(env.X,j)] = 'w'\n",
        "\n",
        "renderPolicy(env,policy)\n",
        "\n"
      ],
      "metadata": {
        "id": "SUbKeUu2ej9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b795522-39b6-4181-829e-1654ac2a6670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>^\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "eval = SimulatePolicy(env, policy, maxSteps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbCYOxYZVYCU",
        "outputId": "b8e71b5b-6c66-4f5c-a003-5b0f60e6dad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*********$$$$$$$$$$A\n",
            "*********$$$$$$$$$$*\n",
            "*********$$$$$$$$$$*\n",
            "*********$$$$$$$$$$*\n",
            "*********$$$$$$$$$$*\n",
            "*#########**********\n",
            "*#########**********\n",
            "*#########**********\n",
            "*#########**********\n",
            "*#########**********\n",
            "Congratulations. You spent 51 steps to reach the Goal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the previously defined policy with Monte Carlo simulation."
      ],
      "metadata": {
        "id": "zti388gigzJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxSteps = 100\n",
        "nSamples = 1000\n",
        "s,g = EvaluatePolicyMC(env, policy, maxSteps, nSamples);"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mSKB6BJJmdjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1c4e6d-694e-4eb0-ccd1-8c579e213f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulating 1.0\n",
            "The goal was rechead 98.9% of the simulations.\n",
            "The average steps in simulations that rechead the goal was 51.346814964610715.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution 2: Analytically Policy Evaluation\n",
        "\n",
        "Expand the cells, before executing them."
      ],
      "metadata": {
        "id": "afYHc7_ZV0mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def policy_evaluation(Environment,pi, gamma, epsilon):\n",
        "    V = {}\n",
        "    for s in Environment.states:\n",
        "        V[s] = 0\n",
        "\n",
        "    res = float('inf')\n",
        "\n",
        "    resolution = 10;\n",
        "\n",
        "    steps = 0\n",
        "\n",
        "    while res > epsilon:\n",
        "        V_old = V.copy()\n",
        "        res = 0\n",
        "\n",
        "        for s in Environment.states:\n",
        "            V[s] = Environment.reward(s,pi[s])\n",
        "            Transitions = Environment.nextState(s,pi[s])\n",
        "            for ss in Transitions:\n",
        "                V[s] = V[s] + gamma*Transitions[ss]*V_old[ss]\n",
        "\n",
        "            if abs(V[s] - V_old[s]) > res:\n",
        "                res = abs(V[s] - V_old[s])\n",
        "\n",
        "\n",
        "        steps += 1\n",
        "        if steps % resolution == 0:\n",
        "            clear_output(wait=True)\n",
        "            print(f'Residual {res}')\n",
        "\n",
        "    return V[Environment.state], V\n",
        "\n",
        "def drawValues(env,V):\n",
        "    img = np.zeros((env.Y,env.X))\n",
        "    for j in range(1,env.Y+1):\n",
        "      for i in range(1,env.X+1):\n",
        "        img[env.Y - j,i-1] = V[(i,j)]\n",
        "    plt.imshow(img, cmap='gray', vmin=min(V.values()), vmax=max(V.values()))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "brfgKXxsWE-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 1\n",
        "epsilon = 0.0000000001\n",
        "env = GridWind_Environment(nX,nY)\n",
        "eval, V = policy_evaluation(env,policy, gamma, epsilon)\n",
        "\n",
        "drawValues(env,V)\n",
        "print(f'The expected cumulative reward is {eval}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "9zBOsO9WHZ1V",
        "outputId": "5fac5a37-5aba-4156-c9cb-813e55e056fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Residual 1.2927614534419263e-10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The expected cumulative reward is -52.005859374440575.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution 3: Evaluation of Uniform Random Policy\n",
        "\n",
        "Expand cells before executing."
      ],
      "metadata": {
        "id": "4G1Hn7nTYU3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_evaluation(Environment, gamma, epsilon):\n",
        "    V = {}\n",
        "    for s in Environment.states:\n",
        "        V[s] = 0\n",
        "\n",
        "    res = float('inf')\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    resolution = 100\n",
        "    steps = 0\n",
        "\n",
        "\n",
        "    while res > epsilon:\n",
        "        V_old = V.copy()\n",
        "        res = 0\n",
        "\n",
        "        for s in Environment.states:\n",
        "          V[s] = 0\n",
        "          for a in Environment.actions:\n",
        "            Transitions = Environment.nextState(s,a)\n",
        "            for ss in Transitions:\n",
        "                V[s] = V[s] + 1/len(Environment.actions)*Transitions[ss]*( Environment.reward(s,a) +  gamma*V_old[ss])\n",
        "\n",
        "          if abs(V[s] - V_old[s]) > res:\n",
        "                res = abs(V[s] - V_old[s])\n",
        "\n",
        "        steps += 1\n",
        "        if steps % resolution == 0:\n",
        "          clear_output(wait=True)\n",
        "          print(f'Residual {res}')\n",
        "\n",
        "    img = np.zeros((env.Y,env.X))\n",
        "    for j in range(1,env.Y+1):\n",
        "      for i in range(1,env.X+1):\n",
        "        img[env.Y - j,i-1] = V[(i,j)]\n",
        "    plt.imshow(img, cmap='gray', vmin=min(V.values()), vmax=max(V.values()))\n",
        "    plt.show()\n",
        "\n",
        "    return V[Environment.state]"
      ],
      "metadata": {
        "id": "sSIy2ZB8NFRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 1\n",
        "epsilon = 0.1\n",
        "env = GridWind_Environment(10,5)\n",
        "eval = random_evaluation(env,gamma, epsilon)\n",
        "\n",
        "print(f'The expected cumulative reward is {eval}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "w28UtNvVNiS8",
        "outputId": "69d17253-a337-4f29-b995-447af911f947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Residual 0.1002076012919133\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The expected cumulative reward is -11174.915382245068.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution 4: Policy Iteration\n",
        "\n",
        "Expand the cells before executing."
      ],
      "metadata": {
        "id": "qhbkLQE5fXLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def policy_evaluation(Environment,pi, gamma, epsilon):\n",
        "    V = {}\n",
        "    for s in Environment.states:\n",
        "        V[s] = 0\n",
        "\n",
        "    res = float('inf')\n",
        "\n",
        "    while res > epsilon:\n",
        "        V_old = V.copy()\n",
        "        res = 0\n",
        "\n",
        "        for s in Environment.states:\n",
        "            V[s] = Environment.reward(s,pi[s])\n",
        "            Transitions = Environment.nextState(s,pi[s])\n",
        "            for ss in Transitions:\n",
        "                V[s] = V[s] + gamma*Transitions[ss]*V_old[ss]\n",
        "\n",
        "            if abs(V[s] - V_old[s]) > res:\n",
        "                res = abs(V[s] - V_old[s])\n",
        "\n",
        "    return V\n",
        "\n",
        "def policy_improvement(Environment,V, gamma):\n",
        "    pi = {}\n",
        "    for s in Environment.states:\n",
        "        Q = {}\n",
        "        for a in Environment.actions:\n",
        "            Q[a] = Environment.reward(s,a)\n",
        "            Transitions = Environment.nextState(s,a)\n",
        "            for ss in Transitions:\n",
        "                Q[a] = Q[a] + gamma*Transitions[ss]*V[ss]\n",
        "\n",
        "        pi[s] = max(Q, key=Q.get)\n",
        "    return pi\n",
        "\n",
        "def policy_iteration(Environment, gamma, eps):\n",
        "\n",
        "    res = 10\n",
        "\n",
        "    policy = {}\n",
        "    for s in Environment.states:\n",
        "      policy[s] = 'd';\n",
        "\n",
        "    V = policy_evaluation(Environment, policy, gamma, eps)\n",
        "\n",
        "    renderPolicy(Environment,policy)\n",
        "\n",
        "    input(f'O valor da política é {V[(1,1)]}. Pressione enter para continuar.')\n",
        "\n",
        "    while res > eps:\n",
        "        policy = policy_improvement(Environment,V, gamma)\n",
        "        V_old = V.copy()\n",
        "        V = policy_evaluation(Environment, policy, gamma, eps)\n",
        "\n",
        "        res = np.max(  np.abs( np.array(list(V.values())) -  np.array(list(V_old.values())) ) )\n",
        "\n",
        "        print(f'Residual {res}')\n",
        "\n",
        "        # clear_output(wait=True)\n",
        "        renderPolicy(Environment,policy)\n",
        "\n",
        "        print(f'O valor da política é {V[(1,1)]}.')\n",
        "        print(f'O valor da política é {np.mean(list(V.values()))}.')\n",
        "        input(f'Pressione enter para continuar.')\n",
        "\n",
        "    return policy\n",
        "\n"
      ],
      "metadata": {
        "id": "Sz23zUKlfgG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.999\n",
        "eps = 0.001\n",
        "env = GridWind_Environment(30,15)\n",
        "\n",
        "policy_iteration(env,gamma,eps);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN_1ziEboPTT",
        "outputId": "27986a13-d6c2-48a7-bf0c-58989bdfeee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "O valor da política é -999.0016985805198. Pressione enter para continuar.\n",
            "Residual 998.0016985805198\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>^^^^^^^^^^^^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^<<<\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^<<<<\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^<<<<<\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^<<<<<<\n",
            "^^^^^^^^^^^^^^^^^^^^^^^<<<<<<<\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "O valor da política é -80.646205438964.\n",
            "O valor da política é -58.54334939421471.\n",
            "Pressione enter para continuar.\n",
            "Residual 35.4644146123186\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^^^>>>>>>>>>>>>>>^^\n",
            "^^^^^^^^^^^^^^>>>>>>>>>>>>^^^^\n",
            "^^^^^^^^^^^^^^^>>>>>>>>>>^^^^^\n",
            "^^^^^^^^^^^^^^^>>>>>>>>>^^^^^^\n",
            "^^^^^^^^^^^^^^^^>>>>>>>^^^^^^^\n",
            "^^^^^^^^^^^^^^^^>>>>>>^^^^^^^^\n",
            "^^^^^^^^^^^^^^^>>>>>>>^^^^^^^^\n",
            "^^^^^^^^^^^^^^>>>>>>>>^^^^^^^^\n",
            "^<^^^^^^^^^^^^>>>>>>>>^^^^^^^^\n",
            "^<<^^^^^^^^^^^>>>>>>>>^^^^^^^^\n",
            "^<<^^^^^^^^^^^>>>>>>>>^^^^^^^^\n",
            "^<<<^^^^^^^^^^>>>>>>>>^^^^^^^^\n",
            "^<<<<^^^^^^^^^>>>>>>>>^^^^^^^^\n",
            "O valor da política é -80.35493634638175.\n",
            "O valor da política é -51.52353317066146.\n",
            "Pressione enter para continuar.\n",
            "Residual 31.785849034376128\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^^>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^^>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^^>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^^^>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^^^>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^^^>vvvvv>>>>>>>>>^\n",
            "^^^^^^^^^^^^^^>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^^>>^^^^^^^>>>>>>>^\n",
            "^<^^^^^^^^^^^>>^^^^^^^>>>>>>>^\n",
            "^<<^^^^^^^^^^>>^^^^^^^>>>>>>>^\n",
            "^<<<^^^^^^^^^>>^^^^^^^>>>>>>>^\n",
            "^<<<<^^^^^^^^>>^^^^^^^>>>>>>>^\n",
            "^<<<<<<^^^^^^>>^^^^^^^>>>>>>>^\n",
            "O valor da política é -80.35493634638175.\n",
            "O valor da política é -46.202758246228555.\n",
            "Pressione enter para continuar.\n",
            "Residual 28.144782918596817\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^>>vvvvvv>>>>>>>>>^\n",
            "^^^^^^^^^^^^>>vvvvvvvvvvvvvv>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^^>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^^^>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^^^^^>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^^^^^^^>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<^^^^^^>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<<<^^^^>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -80.35449666990318.\n",
            "O valor da política é -45.06882457287987.\n",
            "Pressione enter para continuar.\n",
            "Residual 28.890137885902192\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>vvvvvvvv>>>>>>>>>^\n",
            "^^^^^^^^^^^>vvvvvvvvvvvvv>>>>^\n",
            "^^^^^^^^^^^>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^^^^>^>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<<<^^^>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -80.35449666990318.\n",
            "O valor da política é -43.87984882533149.\n",
            "Pressione enter para continuar.\n",
            "Residual 29.868906246826413\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^>>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^>>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^>vvvvvvvvv>>>>>>>>>^\n",
            "^^^^^^^^^^>vvv<vvvvvvvv>>>>>>^\n",
            "^^^^^^^^^^>vvvvvvvvvvvvvv>>>>^\n",
            "^^^^^^^^^^>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^^^>^^>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<<<^^>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -80.35403202046065.\n",
            "O valor da política é -42.71970879854197.\n",
            "Pressione enter para continuar.\n",
            "Residual 30.242426461366392\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^>>>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^>vvvvvvvvv>>>>>>>>>>^\n",
            "^^^^^^^^^>vvvv<vvvvvv>>>>>>>>^\n",
            "^^^^^^^^^>vvvv<vvvvvvvv>>>>>>^\n",
            "^^^^^^^^^>vvvvvvvvvvvvvvv>>>>^\n",
            "^^^^^^^^^>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^^>^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<<<^>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -80.35354098190207.\n",
            "O valor da política é -41.55070261348326.\n",
            "Pressione enter para continuar.\n",
            "Residual 30.380911258484147\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^>vvvvvvvv>>>>>>>>>>>>^\n",
            "^^^^^^^^>vvvvv<vvvv>>>>>>>>>>^\n",
            "^^^^^^^^>vvvvv<vvvvvv>>>>>>>>^\n",
            "^^^^^^^^>vvvvvvvvvvvvvv>>>>>>^\n",
            "^^^^^^^^>vvvvvvvvvvvvvvvv>>>>^\n",
            "^^^^^^^^>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^>^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<<<>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -80.352473667854.\n",
            "O valor da política é -40.36893530423902.\n",
            "Pressione enter para continuar.\n",
            "Residual 30.454042116665256\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>^\n",
            ">>>>>>>>vvvvvvvvv>>>>>>>>>>>>^\n",
            "^^^^^^^>vvvvvv<vvv>>>>>>>>>>>^\n",
            "^^^^^^^>vvvvvv<vvvv>>>>>>>>>>^\n",
            "^^^^^^^>vvvvvv<vvvvvv>>>>>>>>^\n",
            "^^^^^^^>vvvvvvvvvvvvvvv>>>>>>^\n",
            "^^^^^^^>vvvvvvvvvvvvvvvvv>>>>^\n",
            "^^^^^^^>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^>^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^>>^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^^>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<^>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<<>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -61.660953429863596.\n",
            "O valor da política é -34.77237813470497.\n",
            "Pressione enter para continuar.\n",
            "Residual 18.239705035380744\n",
            "\n",
            "vvvvvvvvvvvvvvvv>>>>>>>>>>>>>^\n",
            ">>>>>>>vvvvvvv<vv>>>>>>>>>>>>^\n",
            "^^^^^^>vvvvvvv<<vv>>>>>>>>>>>^\n",
            "^^^^^^>vvvvvvv<<vvv>>>>>>>>>>^\n",
            "^^^^^^>vvvvvvv<vvvvvv>>>>>>>>^\n",
            "^^^^^^>vvvvvvvvvvvvvvvv>>>>>>^\n",
            "^^^^^^>vvvvvvvvvvvvvvvvvv>>>>^\n",
            "^^^^^^>>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -61.63966469072528.\n",
            "O valor da política é -33.767692372332974.\n",
            "Pressione enter para continuar.\n",
            "Residual 11.475412100613028\n",
            "\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            ">>>>>>vvvvvvvv<<<>>>>>>>>>>>>^\n",
            "^^^^^>vvvvvvvv<<vv>>>>>>>>>>>^\n",
            "^^^^^>vvvvvvvv<<vvv>>>>>>>>>>^\n",
            "^^^^^>vvvvvvvv<vvvvvv>>>>>>>>^\n",
            "^^^^^>vvvvvvvvvvvvvvvvv>>>>>>^\n",
            "^^^^^>vvvvvvvvvvvvvvvvvvv>>>>^\n",
            "^^^^^>>>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^>^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^>^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -61.63505242670285.\n",
            "O valor da política é -33.554241448525204.\n",
            "Pressione enter para continuar.\n",
            "Residual 11.461169116796256\n",
            "\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            ">>>>>vvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "^^^^>vvvvvvvvv<<vv>>>>>>>>>>>^\n",
            "^^^^>vvvvvvvvv<<vvv>>>>>>>>>>^\n",
            "^^^^>vvvvvvvvv<vvvvvv>>>>>>>>^\n",
            "^^^^>vvvvvvvvvvvvvvvvvv>>>>>>^\n",
            "^^^^>vvvvvvvvvvvvvvvvvvvv>>>>^\n",
            "^^^^>>>>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<>>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<>>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<>>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -61.63338341141297.\n",
            "O valor da política é -33.33725435069147.\n",
            "Pressione enter para continuar.\n",
            "Residual 11.44835160765875\n",
            "\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            ">>>>vvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "^^^>vvvvvvvvvv<<vv>>>>>>>>>>>^\n",
            "^^^>vvvvvvvvvv<<vvv>>>>>>>>>>^\n",
            "^^^>vvvvvvvvvv<vvvvvv>>>>>>>>^\n",
            "^^^>vvvvvvvvvvvvvvvvvvv>>>>>>^\n",
            "^^^>vvvvvvvvvvvvvvvvvvvvv>>>>^\n",
            "^^^>>>>>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^>^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^>^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<>>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<>>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -61.63209874679192.\n",
            "O valor da política é -33.20557673057996.\n",
            "Pressione enter para continuar.\n",
            "Residual 11.437069435094358\n",
            "\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            ">>>vvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "^^>vvvvvvvvvvv<<vv>>>>>>>>>>>^\n",
            "^^>vvvvvvvvvvv<<vvv>>>>>>>>>>^\n",
            "^^>vvvvvvvvvvv<vvvvvv>>>>>>>>^\n",
            "^^>vvvvvvvvvvvvvvvvvvvv>>>>>>^\n",
            "^^>vvvvvvvvvvvvvvvvvvvvvv>>>>^\n",
            "^^>>>>>>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<>>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<>>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -61.630708545263076.\n",
            "O valor da política é -32.980635902211354.\n",
            "Pressione enter para continuar.\n",
            "Residual 11.424701579577544\n",
            "\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            ">>vvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "^>vvvvvvvvvvvv<<vv>>>>>>>>>>>^\n",
            "^>vvvvvvvvvvvv<<vvv>>>>>>>>>>^\n",
            "^>vvvvvvvvvvvv<vvvvvv>>>>>>>>^\n",
            "^>vvvvvvvvvvvvvvvvvvvvv>>>>>>^\n",
            "^>vvvvvvvvvvvvvvvvvvvvvvv>>>>^\n",
            "^>>>>>>>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^>^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^>^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<>>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -61.63023064239019.\n",
            "O valor da política é -32.843350959422004.\n",
            "Pressione enter para continuar.\n",
            "Residual 11.415770314242408\n",
            "\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            ">vvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            ">vvvvvvvvvvvvv<<vv>>>>>>>>>>>^\n",
            ">vvvvvvvvvvvvv<<vvv>>>>>>>>>>^\n",
            ">vvvvvvvvvvvvv<vvvvvv>>>>>>>>^\n",
            ">vvvvvvvvvvvvvvvvvvvvvv>>>>>>^\n",
            ">vvvvvvvvvvvvvvvvvvvvvvvv>>>>^\n",
            ">>>>>>>>>>>>>>vvvvvvvvvvvvv>>^\n",
            ">^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^^^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<>>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -52.95114987511516.\n",
            "O valor da política é -32.14548875954327.\n",
            "Pressione enter para continuar.\n",
            "Residual 5.837665288828461\n",
            "\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<vv>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<vvv>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<vvvvvv>>>>>>>>^\n",
            "vvvvvvvvvvvvvvvvvvvvvvv>>>>>>^\n",
            "vvvvvvvvvvvvvvvvvvvvvvvvv>>>>^\n",
            ">>>>>>>>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^^^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<>>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -50.291960757332916.\n",
            "O valor da política é -31.921844931938306.\n",
            "Pressione enter para continuar.\n",
            "Residual 2.0208826779949476\n",
            "\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<vv>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<vvv>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<vvvvvv>>>>>>>>^\n",
            "vvvvvvvvvvvvvvvvvvvvvvv>>>>>>^\n",
            "vvvvvvvvvvvvvvvvvvvvvvvvv>>>>^\n",
            ">>>>>>>>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<^^>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -50.29027190743531.\n",
            "O valor da política é -31.894444923973545.\n",
            "Pressione enter para continuar.\n",
            "Residual 0.025646689630512753\n",
            "\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<vv>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<vvv>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<vvvvvv>>>>>>>>^\n",
            "vvvvvvvvvvvvvvvvvvvvvvv>>>>>>^\n",
            "vvvvvvvvvvvvvvvvvvvvvvvvv>>>>^\n",
            ">>>>>>>>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<^>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -50.29027078401732.\n",
            "O valor da política é -31.89429050508526.\n",
            "Pressione enter para continuar.\n",
            "Residual 0.0\n",
            "\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<vv>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<vvv>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<vvvvvv>>>>>>>>^\n",
            "vvvvvvvvvvvvvvvvvvvvvvv>>>>>>^\n",
            "vvvvvvvvvvvvvvvvvvvvvvvvv>>>>^\n",
            ">>>>>>>>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<^>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -50.29027078401732.\n",
            "O valor da política é -31.89429050508526.\n",
            "Pressione enter para continuar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution 5: Value Iteration\n",
        "\n",
        "Expand the cells before executing."
      ],
      "metadata": {
        "id": "uPsitTYLfgeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def value_iteration(Environment,gamma, eps):\n",
        "    V = {}\n",
        "    for s in Environment.states:\n",
        "        V[s] = 0\n",
        "\n",
        "    res = float('inf')\n",
        "\n",
        "    if gamma < 1:\n",
        "        epsilon = eps*(1-gamma)/(2*gamma)\n",
        "    else:\n",
        "        epsilon = eps\n",
        "\n",
        "    while res > epsilon:\n",
        "        V_old = V.copy()\n",
        "        res = 0\n",
        "\n",
        "#       Encontra a função valor epsilon-ótima\n",
        "        for s in Environment.states:\n",
        "            Q = {}\n",
        "            for a in Environment.actions:\n",
        "                Q[a] = Environment.reward(s,a)\n",
        "                Transitions = Environment.nextState(s,a)\n",
        "                for ss in Transitions:\n",
        "                    Q[a] = Q[a] + gamma*Transitions[ss]*V_old[ss]\n",
        "\n",
        "            V[s] = max(Q.values())\n",
        "\n",
        "            if abs(V[s] - V_old[s]) > res:\n",
        "                res = abs(V[s] - V_old[s])\n",
        "\n",
        "#   Extrai a política epsilon-ótima\n",
        "    pi = {}\n",
        "    for s in Environment.states:\n",
        "        Q = {}\n",
        "        for a in Environment.actions:\n",
        "            Q[a] = Environment.reward(s,a)\n",
        "            Transitions = Environment.nextState(s,a)\n",
        "            for ss in Transitions:\n",
        "                Q[a] = Q[a] + gamma*Transitions[ss]*V[ss]\n",
        "\n",
        "        pi[s] = max(Q, key=Q.get)\n",
        "\n",
        "\n",
        "    return pi, V[Environment.state]"
      ],
      "metadata": {
        "id": "XsMK3zyiU3fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.999\n",
        "epsilon = 0.000001\n",
        "env = GridWind_Environment(30,15)\n",
        "policy, eval = value_iteration(env,gamma, epsilon)\n",
        "renderPolicy(env,policy)\n",
        "print(f'O valor da política é {eval}. Pressione enter para continuar.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlWWyLYDU61o",
        "outputId": "8084d759-8fbf-4b2f-a46f-fc5d412ab6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<<>>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<vv>>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<<vvv>>>>>>>>>>^\n",
            "vvvvvvvvvvvvvv<vvvvvv>>>>>>>>^\n",
            "vvvvvvvvvvvvvvvvvvvvvvv>>>>>>^\n",
            "vvvvvvvvvvvvvvvvvvvvvvvvv>>>>^\n",
            ">>>>>>>>>>>>>>vvvvvvvvvvvvv>>^\n",
            "^^^^^^^^^^^^>>>>>>>>>>>>>>>>>^\n",
            "^^^^^^^^^^^>>>>^^^^^^^^^^^^^^^\n",
            "^<^^^^^^^^>>>>>^^^^^^^^^^^^^^^\n",
            "^<<^^^^^^>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<^^^^>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<^>>>>>>>>^^^^^^^^^^^^^^^\n",
            "^<<<<<>>>>>>>>>^^^^^^^^^^^^^^^\n",
            "O valor da política é -50.29277719551545. Pressione enter para continuar.\n"
          ]
        }
      ]
    }
  ]
}